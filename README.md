# Happy_Monk_ANN_Activation_Function

The choice of Activation Functions (AF) has proven to be an important factor that affects the performance of an Artificial Neural Network (ANN). Use a 1-hidden layer neural network model that adapts to the most suitable activation function according to the data-set.
Here I use Wisconsin Breast Cancer dataset 
In hidden layer of ANN  tested by changing the activation function with relu, sigmoid, Tanh, softmax, softsign, swish. 
Here Sigmoid and Tanh activation function is giving the best accuracy score.
